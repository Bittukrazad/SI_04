{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpXyrI4VNcBcrMI1puqnvB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","\n","# Load dataset\n","data = pd.read_csv('/content/amazon_reviews.csv')\n","\n","# Preview the dataset\n","print(data.head())\n","\n","# Check for missing values\n","data = data.dropna()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8pIqzw2oAGM","executionInfo":{"status":"ok","timestamp":1729205627455,"user_tz":-330,"elapsed":390,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"82e668ae-154a-4d62-f245-e6c581a9d280"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["   Unnamed: 0        asin   helpful  overall  \\\n","0           0  0528881469    [0, 0]      5.0   \n","1           1  0528881469  [12, 15]      1.0   \n","2           2  0528881469  [43, 45]      3.0   \n","3           3  0528881469   [9, 10]      2.0   \n","4           4  0528881469    [0, 0]      1.0   \n","\n","                                          reviewText   reviewTime  \\\n","0  We got this GPS for my husband who is an (OTR)...   06 2, 2013   \n","1  I'm a professional OTR truck driver, and I bou...  11 25, 2010   \n","2  Well, what can I say.  I've had this unit in m...   09 9, 2010   \n","3  Not going to write a long review, even thought...  11 24, 2010   \n","4  I've had mine for a year and here's what we go...  09 29, 2011   \n","\n","       reviewerID              reviewerName  \\\n","0   AO94DHGC771SJ                   amazdnu   \n","1   AMO214LNFCEI4           Amazon Customer   \n","2  A3N7T0DY83Y4IG             C. A. Freeman   \n","3  A1H8PY3QHMQQA0  Dave M. Shaw \"mack dave\"   \n","4  A24EV6RXELQZ63               Wayne Smith   \n","\n","                                  summary  unixReviewTime  \n","0                         Gotta have GPS!    1.370131e+09  \n","1                       Very Disappointed    1.290643e+09  \n","2                          1st impression    1.283990e+09  \n","3                 Great grafics, POOR GPS    1.290557e+09  \n","4  Major issues, only excuses for support    1.317254e+09  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","\n","# Load dataset\n","data = pd.read_csv('/content/amazon_reviews.csv')\n","\n","# Preview the dataset\n","print(data.head())\n","\n","# Check for missing values\n","data = data.dropna()\n","\n","# Download necessary NLTK resources\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","def preprocess_text(text):\n","    # Tokenize the text\n","    tokens = word_tokenize(text)\n","    # Remove punctuation and convert to lowercase\n","    tokens = [word.lower() for word in tokens if word.isalpha()]\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","# Check the actual column names in your dataframe\n","print(data.columns)\n","\n","# Assuming the review column is named 'reviews.text', adjust accordingly\n","# Apply the preprocessing function to the reviews\n","# Replace 'reviews.text' with the actual column name from data.columns output\n","data['Cleaned_Review'] = data['reviewText'].apply(preprocess_text) # Example: Using 'reviewText' if it is the correct column name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2rJO9HLtDFq","executionInfo":{"status":"ok","timestamp":1729205918627,"user_tz":-330,"elapsed":2708,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"16e67350-9c60-4fbb-8903-a95fda33604a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["   Unnamed: 0        asin   helpful  overall  \\\n","0           0  0528881469    [0, 0]      5.0   \n","1           1  0528881469  [12, 15]      1.0   \n","2           2  0528881469  [43, 45]      3.0   \n","3           3  0528881469   [9, 10]      2.0   \n","4           4  0528881469    [0, 0]      1.0   \n","\n","                                          reviewText   reviewTime  \\\n","0  We got this GPS for my husband who is an (OTR)...   06 2, 2013   \n","1  I'm a professional OTR truck driver, and I bou...  11 25, 2010   \n","2  Well, what can I say.  I've had this unit in m...   09 9, 2010   \n","3  Not going to write a long review, even thought...  11 24, 2010   \n","4  I've had mine for a year and here's what we go...  09 29, 2011   \n","\n","       reviewerID              reviewerName  \\\n","0   AO94DHGC771SJ                   amazdnu   \n","1   AMO214LNFCEI4           Amazon Customer   \n","2  A3N7T0DY83Y4IG             C. A. Freeman   \n","3  A1H8PY3QHMQQA0  Dave M. Shaw \"mack dave\"   \n","4  A24EV6RXELQZ63               Wayne Smith   \n","\n","                                  summary  unixReviewTime  \n","0                         Gotta have GPS!    1.370131e+09  \n","1                       Very Disappointed    1.290643e+09  \n","2                          1st impression    1.283990e+09  \n","3                 Great grafics, POOR GPS    1.290557e+09  \n","4  Major issues, only excuses for support    1.317254e+09  \n","Index(['Unnamed: 0', 'asin', 'helpful', 'overall', 'reviewText', 'reviewTime',\n","       'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'],\n","      dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","\n","# Load dataset\n","data = pd.read_csv('/content/amazon_reviews.csv')\n","\n","# Preview the dataset\n","print(data.head())\n","\n","# Check for missing values\n","data = data.dropna()\n","\n","# Download necessary NLTK resources\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","def preprocess_text(text):\n","    # Tokenize the text\n","    tokens = word_tokenize(text)\n","    # Remove punctuation and convert to lowercase\n","    tokens = [word.lower() for word in tokens if word.isalpha()]\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","# Check the actual column names in your dataframe\n","print(data.columns)\n","\n","# Assuming the review column is named 'reviews.text', adjust accordingly\n","# Apply the preprocessing function to the reviews\n","# Replace 'reviews.text' with the actual column name from data.columns output\n","data['Cleaned_Review'] = data['reviewText'].apply(preprocess_text) # Example: Using 'reviewText' if it is the correct column name\n","\n","# ***CHANGE***: Replace 'Sentiment' with the actual column name for sentiment in your dataset\n","# Check the output of data.columns to find the correct column name\n","# For example, if the sentiment column is named 'overall', use:\n","y = data['overall']\n","# If it is rating use:\n","# y = data['rating']\n","# Assuming your sentiment data is 'overall' column as amazon_reviews.csv dataset\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(data['Cleaned_Review'])\n","\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8b2Q75K4tijS","executionInfo":{"status":"ok","timestamp":1729206044942,"user_tz":-330,"elapsed":1846,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"dde21703-a1e9-48d7-82b1-5ff7a256ad93"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["   Unnamed: 0        asin   helpful  overall  \\\n","0           0  0528881469    [0, 0]      5.0   \n","1           1  0528881469  [12, 15]      1.0   \n","2           2  0528881469  [43, 45]      3.0   \n","3           3  0528881469   [9, 10]      2.0   \n","4           4  0528881469    [0, 0]      1.0   \n","\n","                                          reviewText   reviewTime  \\\n","0  We got this GPS for my husband who is an (OTR)...   06 2, 2013   \n","1  I'm a professional OTR truck driver, and I bou...  11 25, 2010   \n","2  Well, what can I say.  I've had this unit in m...   09 9, 2010   \n","3  Not going to write a long review, even thought...  11 24, 2010   \n","4  I've had mine for a year and here's what we go...  09 29, 2011   \n","\n","       reviewerID              reviewerName  \\\n","0   AO94DHGC771SJ                   amazdnu   \n","1   AMO214LNFCEI4           Amazon Customer   \n","2  A3N7T0DY83Y4IG             C. A. Freeman   \n","3  A1H8PY3QHMQQA0  Dave M. Shaw \"mack dave\"   \n","4  A24EV6RXELQZ63               Wayne Smith   \n","\n","                                  summary  unixReviewTime  \n","0                         Gotta have GPS!    1.370131e+09  \n","1                       Very Disappointed    1.290643e+09  \n","2                          1st impression    1.283990e+09  \n","3                 Great grafics, POOR GPS    1.290557e+09  \n","4  Major issues, only excuses for support    1.317254e+09  \n","Index(['Unnamed: 0', 'asin', 'helpful', 'overall', 'reviewText', 'reviewTime',\n","       'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'],\n","      dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Train the model\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test)\n"],"metadata":{"id":"8NcPwGcaqtBk","executionInfo":{"status":"ok","timestamp":1729206061047,"user_tz":-330,"elapsed":412,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","\n","# Classification report\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5bTDK8pq0VK","executionInfo":{"status":"ok","timestamp":1729206066110,"user_tz":-330,"elapsed":419,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"5053c890-1244-4303-b802-39811e629612"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 61.81%\n","              precision    recall  f1-score   support\n","\n","         1.0       0.75      0.38      0.50        24\n","         2.0       0.33      0.08      0.13        12\n","         3.0       0.50      0.11      0.18        18\n","         4.0       0.13      0.07      0.09        29\n","         5.0       0.66      0.94      0.78       116\n","\n","    accuracy                           0.62       199\n","   macro avg       0.48      0.32      0.34       199\n","weighted avg       0.56      0.62      0.55       199\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","# Save the model\n","joblib.dump(model, 'sentiment_analysis_model.pkl')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjI_Y_liubVP","executionInfo":{"status":"ok","timestamp":1729206296590,"user_tz":-330,"elapsed":605,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"bbe599ca-1e68-4bf2-a583-d30d43618599"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['sentiment_analysis_model.pkl']"]},"metadata":{},"execution_count":19}]}]}